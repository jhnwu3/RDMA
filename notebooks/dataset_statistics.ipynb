{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import sys\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.insert(0, parent_dir)\n",
    "# Set the parent directory as the current directory\n",
    "os.chdir(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Dataset Statistics ===\n",
      "\n",
      "Total Clinical Notes: 116\n",
      "Total Words: 33,824\n",
      "Total Characters: 216,187\n",
      "Total Sentences: 2,187\n",
      "Unique Words: 5,591\n",
      "\n",
      "--- Per Note Statistics ---\n",
      "Words per note: Mean=291.6, Median=271.5\n",
      "Characters per note: Mean=1863.7, Median=1738.0\n",
      "Sentences per note: Mean=18.9, Median=17.0\n",
      "Unique words per note: Mean=178.2, Median=164.5\n",
      "\n",
      "--- Word Count Percentiles ---\n",
      "25%: 203.0\n",
      "50%: 271.5\n",
      "75%: 372.8\n",
      "90%: 439.0\n",
      "\n",
      "--- Top 10 Most Frequent Words ---\n",
      "and: 1,318\n",
      "the: 1,299\n",
      "of: 1,208\n",
      "was: 811\n",
      "a: 783\n",
      "with: 582\n",
      "in: 465\n",
      "to: 459\n",
      "were: 307\n",
      "for: 260\n",
      "\n",
      "Vocabulary Richness (type-token ratio): 0.1653\n",
      "Average word length: 7.58 characters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "def compute_dataset_statistics(data):\n",
    "    \"\"\"\n",
    "    Compute statistics about a dataset of clinical notes.\n",
    "    \n",
    "    Args:\n",
    "        data: Dictionary of note_id -> {\"clinical_text\": text_content, ...}\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary containing dataset statistics.\n",
    "    \"\"\"\n",
    "    # Initialize counters and lists for collecting stats\n",
    "    total_notes = len(data)\n",
    "    all_word_counts = []\n",
    "    all_char_counts = []\n",
    "    all_sentence_counts = []\n",
    "    all_unique_word_counts = []\n",
    "    word_frequencies = Counter()\n",
    "    \n",
    "    # Process each note\n",
    "    for note_id, note_data in data.items():\n",
    "        text = note_data.get(\"clinical_text\", \"\")\n",
    "        \n",
    "        # Skip if text is missing\n",
    "        if not text:\n",
    "            continue\n",
    "            \n",
    "        # Character count\n",
    "        char_count = len(text)\n",
    "        all_char_counts.append(char_count)\n",
    "        \n",
    "        # Word count (split on whitespace)\n",
    "        words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "        word_count = len(words)\n",
    "        all_word_counts.append(word_count)\n",
    "        \n",
    "        # Update word frequency counter\n",
    "        word_frequencies.update(words)\n",
    "        \n",
    "        # Unique word count\n",
    "        unique_words = len(set(words))\n",
    "        all_unique_word_counts.append(unique_words)\n",
    "        \n",
    "        # Approximate sentence count (split on ., !, ?)\n",
    "        sentences = re.split(r'[.!?]+', text)\n",
    "        sentence_count = len([s for s in sentences if s.strip()])\n",
    "        all_sentence_counts.append(sentence_count)\n",
    "    \n",
    "    # Calculate statistics\n",
    "    stats = {\n",
    "        \"total_notes\": total_notes,\n",
    "        \n",
    "        # Character statistics\n",
    "        \"total_chars\": sum(all_char_counts),\n",
    "        \"mean_chars_per_note\": np.mean(all_char_counts),\n",
    "        \"median_chars_per_note\": np.median(all_char_counts),\n",
    "        \"min_chars\": min(all_char_counts),\n",
    "        \"max_chars\": max(all_char_counts),\n",
    "        \n",
    "        # Word statistics\n",
    "        \"total_words\": sum(all_word_counts),\n",
    "        \"mean_words_per_note\": np.mean(all_word_counts),\n",
    "        \"median_words_per_note\": np.median(all_word_counts),\n",
    "        \"min_words\": min(all_word_counts),\n",
    "        \"max_words\": max(all_word_counts),\n",
    "        \n",
    "        # Unique words\n",
    "        \"total_unique_words\": len(word_frequencies),\n",
    "        \"mean_unique_words_per_note\": np.mean(all_unique_word_counts),\n",
    "        \"median_unique_words_per_note\": np.median(all_unique_word_counts),\n",
    "        \n",
    "        # Sentence statistics\n",
    "        \"total_sentences\": sum(all_sentence_counts),\n",
    "        \"mean_sentences_per_note\": np.mean(all_sentence_counts),\n",
    "        \"median_sentences_per_note\": np.median(all_sentence_counts),\n",
    "        \n",
    "        # Calculate average word length\n",
    "        \"mean_word_length\": np.mean([len(word) for word in word_frequencies.keys()]),\n",
    "        \n",
    "        # Vocabulary richness (type-token ratio for the entire corpus)\n",
    "        \"vocabulary_richness\": len(word_frequencies) / sum(all_word_counts),\n",
    "    }\n",
    "    \n",
    "    # Add distribution data\n",
    "    stats[\"char_count_percentiles\"] = {\n",
    "        \"25%\": np.percentile(all_char_counts, 25),\n",
    "        \"50%\": np.percentile(all_char_counts, 50),\n",
    "        \"75%\": np.percentile(all_char_counts, 75),\n",
    "        \"90%\": np.percentile(all_char_counts, 90),\n",
    "    }\n",
    "    \n",
    "    stats[\"word_count_percentiles\"] = {\n",
    "        \"25%\": np.percentile(all_word_counts, 25),\n",
    "        \"50%\": np.percentile(all_word_counts, 50),\n",
    "        \"75%\": np.percentile(all_word_counts, 75),\n",
    "        \"90%\": np.percentile(all_word_counts, 90),\n",
    "    }\n",
    "    \n",
    "    # Top 10 most frequent words\n",
    "    stats[\"top_10_words\"] = dict(word_frequencies.most_common(10))\n",
    "    \n",
    "    return stats\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    from utils.data import read_json_file\n",
    "    \n",
    "    data = read_json_file(\"data/dataset/mine_hpo.json\")\n",
    "    stats = compute_dataset_statistics(data)\n",
    "    \n",
    "    # Print formatted statistics\n",
    "    print(\"\\n=== Dataset Statistics ===\\n\")\n",
    "    \n",
    "    print(f\"Total Clinical Notes: {stats['total_notes']}\")\n",
    "    print(f\"Total Words: {stats['total_words']:,}\")\n",
    "    print(f\"Total Characters: {stats['total_chars']:,}\")\n",
    "    print(f\"Total Sentences: {stats['total_sentences']:,}\")\n",
    "    print(f\"Unique Words: {stats['total_unique_words']:,}\")\n",
    "    \n",
    "    print(\"\\n--- Per Note Statistics ---\")\n",
    "    print(f\"Words per note: Mean={stats['mean_words_per_note']:.1f}, Median={stats['median_words_per_note']:.1f}\")\n",
    "    print(f\"Characters per note: Mean={stats['mean_chars_per_note']:.1f}, Median={stats['median_chars_per_note']:.1f}\")\n",
    "    print(f\"Sentences per note: Mean={stats['mean_sentences_per_note']:.1f}, Median={stats['median_sentences_per_note']:.1f}\")\n",
    "    print(f\"Unique words per note: Mean={stats['mean_unique_words_per_note']:.1f}, Median={stats['median_unique_words_per_note']:.1f}\")\n",
    "    \n",
    "    print(\"\\n--- Word Count Percentiles ---\")\n",
    "    percentiles = stats[\"word_count_percentiles\"]\n",
    "    for name, value in percentiles.items():\n",
    "        print(f\"{name}: {value:.1f}\")\n",
    "        \n",
    "    print(\"\\n--- Top 10 Most Frequent Words ---\")\n",
    "    for word, count in stats[\"top_10_words\"].items():\n",
    "        print(f\"{word}: {count:,}\")\n",
    "    \n",
    "    print(f\"\\nVocabulary Richness (type-token ratio): {stats['vocabulary_richness']:.4f}\")\n",
    "    print(f\"Average word length: {stats['mean_word_length']:.2f} characters\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hporag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
